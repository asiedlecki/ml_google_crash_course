{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52479eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f912c65",
   "metadata": {},
   "source": [
    "# Validation Sets and Test Sets\n",
    "\n",
    "The previous Colab exercises evaluated the trained model against the training set, which does not provide a strong signal about the quality of your model. In this Colab, you'll experiment with validation sets and test sets.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266b53a",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "After doing this Colab, you'll know how to do the following:\n",
    "\n",
    "  * Split a [training set](https://developers.google.com/machine-learning/glossary/#training_set) into a smaller training set and a [validation set](https://developers.google.com/machine-learning/glossary/#validation_set).\n",
    "  * Analyze deltas between training set and validation set results.\n",
    "  * Test the trained model with a [test set](https://developers.google.com/machine-learning/glossary/#test_set) to determine whether your trained model is [overfitting](https://developers.google.com/machine-learning/glossary/#overfitting).\n",
    "  * Detect and fix a common training problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b3b72",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "As in the previous exercise, this exercise uses the [California Housing dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) to predict the `median_house_value` at the city block level.  Like many \"famous\" datasets, the California Housing Dataset actually consists of two separate datasets, each living in separate .csv files:\n",
    "\n",
    "* The training set is in `california_housing_train.csv`.\n",
    "* The test set is in `california_housing_test.csv`.\n",
    "\n",
    "You'll create the validation set by dividing the downloaded training set into two parts:\n",
    "\n",
    "* a smaller training set  \n",
    "* a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9fdee",
   "metadata": {},
   "source": [
    "## Import relevant modules\n",
    "\n",
    "As before, this first code cell imports the necessary modules and sets a few display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69263234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed984d",
   "metadata": {},
   "source": [
    "## Load the datasets from the internet\n",
    "\n",
    "The following code cell loads the separate .csv files and creates the following two pandas DataFrames:\n",
    "\n",
    "* `train_df`, which contains the training set.\n",
    "* `test_df`, which contains the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e15084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45676f3a",
   "metadata": {},
   "source": [
    "## Scale the label values\n",
    "\n",
    "The following code cell scales the `median_house_value`. \n",
    "See the previous Colab exercise for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0f430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 1000.0\n",
    "\n",
    "# Scale the training set's label.\n",
    "train_df[\"median_house_value\"] /= scale_factor \n",
    "\n",
    "# Scale the test set's label\n",
    "test_df[\"median_house_value\"] /= scale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466af322",
   "metadata": {},
   "source": [
    "## Load the functions that build and train a model\n",
    "\n",
    "The following code cell defines two functions:\n",
    "\n",
    "  * `build_model`, which defines the model's topography.\n",
    "  * `train_model`, which will ultimately train the model, outputting not only the loss value for the training set but also the loss value for the validation set. \n",
    "\n",
    "Since you don't need to understand model building code right now, we've hidden this code cell. As always, you must run hidden code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda0e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the build_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the functions that build and train a model\n",
    "def build_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add one linear layer to the model to yield a simple linear regressor.\n",
    "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
    "\n",
    "  # Compile the model topography into code that TensorFlow can efficiently\n",
    "  # execute. Configure training to minimize the model's mean squared error. \n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model               \n",
    "\n",
    "\n",
    "def train_model(model, df, feature, label, my_epochs, \n",
    "                my_batch_size=None, my_validation_split=0.1):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  history = model.fit(x=df[feature],\n",
    "                      y=df[label],\n",
    "                      batch_size=my_batch_size,\n",
    "                      epochs=my_epochs,\n",
    "                      validation_split=my_validation_split)\n",
    "\n",
    "  # Gather the model's trained weight and bias.\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  # The list of epochs is stored separately from the \n",
    "  # rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # Isolate the root mean squared error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return epochs, rmse, history.history   \n",
    "\n",
    "print(\"Defined the build_model and train_model functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a4cd6",
   "metadata": {},
   "source": [
    "## Define plotting functions\n",
    "\n",
    "The `plot_the_loss_curve` function plots loss vs. epochs for both the training set and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34d9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function\n",
    "\n",
    "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n",
    "  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n",
    "  plt.legend()\n",
    "  \n",
    "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
    "  # is often substantially greater than the loss for other epochs.\n",
    "  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n",
    "  highest_loss = max(merged_mae_lists)\n",
    "  lowest_loss = min(merged_mae_lists)\n",
    "  delta = highest_loss - lowest_loss\n",
    "  print(delta)\n",
    "\n",
    "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
    "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
    "   \n",
    "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
    "  plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ec2ab",
   "metadata": {},
   "source": [
    "## Task 1: Experiment with the validation split\n",
    "\n",
    "In the following code cell, you'll see a variable named `validation_split`, which we've initialized at 0.2.  The `validation_split` variable specifies the proportion of the original training set that will serve as the validation set. The original training set contains 17,000 examples. Therefore, a `validation_split` of 0.2 means that:\n",
    "\n",
    "* 17,000 * 0.2 ~= 3,400 examples will become the validation set.\n",
    "* 17,000 * 0.8 ~= 13,600 examples will become the new training set.\n",
    "\n",
    "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
    "\n",
    "* The training set.\n",
    "* And the validation set.\n",
    "\n",
    "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical. However, the loss curves and final loss values are **not** almost identical. Hmm, that's odd.  \n",
    "\n",
    "Experiment with two or three different values of `validation_split`.  Do different values of `validation_split` fix the problem? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab27165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 51621.4030 - root_mean_squared_error: 227.1651 - val_loss: 38913.9922 - val_root_mean_squared_error: 197.2663\n",
      "Epoch 2/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 35896.5081 - root_mean_squared_error: 189.4065 - val_loss: 25757.9238 - val_root_mean_squared_error: 160.4928\n",
      "Epoch 3/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 23749.8292 - root_mean_squared_error: 154.0211 - val_loss: 16152.1934 - val_root_mean_squared_error: 127.0913\n",
      "Epoch 4/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 14894.1726 - root_mean_squared_error: 121.9636 - val_loss: 9996.5566 - val_root_mean_squared_error: 99.9828\n",
      "Epoch 5/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9451.0878 - root_mean_squared_error: 97.1588 - val_loss: 7165.6675 - val_root_mean_squared_error: 84.6503\n",
      "Epoch 6/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7341.6382 - root_mean_squared_error: 85.6715 - val_loss: 6801.4883 - val_root_mean_squared_error: 82.4711\n",
      "Epoch 7/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7486.0680 - root_mean_squared_error: 86.4791 - val_loss: 6802.6812 - val_root_mean_squared_error: 82.4784\n",
      "Epoch 8/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7033.3047 - root_mean_squared_error: 83.8605 - val_loss: 6808.9414 - val_root_mean_squared_error: 82.5163\n",
      "Epoch 9/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 6990.4169 - root_mean_squared_error: 83.5941 - val_loss: 6810.8804 - val_root_mean_squared_error: 82.5281\n",
      "Epoch 10/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7182.7262 - root_mean_squared_error: 84.7441 - val_loss: 6815.2808 - val_root_mean_squared_error: 82.5547\n",
      "Epoch 11/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7107.8602 - root_mean_squared_error: 84.2956 - val_loss: 6819.7524 - val_root_mean_squared_error: 82.5818\n",
      "Epoch 12/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7240.8636 - root_mean_squared_error: 85.0873 - val_loss: 6824.2559 - val_root_mean_squared_error: 82.6091\n",
      "Epoch 13/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7029.2680 - root_mean_squared_error: 83.8209 - val_loss: 6823.4961 - val_root_mean_squared_error: 82.6045\n",
      "Epoch 14/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7202.4277 - root_mean_squared_error: 84.8603 - val_loss: 6826.2075 - val_root_mean_squared_error: 82.6209\n",
      "Epoch 15/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7045.3505 - root_mean_squared_error: 83.9200 - val_loss: 6827.5059 - val_root_mean_squared_error: 82.6287\n",
      "Epoch 16/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7149.5098 - root_mean_squared_error: 84.5485 - val_loss: 6831.3418 - val_root_mean_squared_error: 82.6519\n",
      "Epoch 17/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7317.2416 - root_mean_squared_error: 85.5352 - val_loss: 6833.7578 - val_root_mean_squared_error: 82.6665\n",
      "Epoch 18/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7205.5718 - root_mean_squared_error: 84.8427 - val_loss: 6832.9331 - val_root_mean_squared_error: 82.6616\n",
      "Epoch 19/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 6910.5004 - root_mean_squared_error: 83.1167 - val_loss: 6836.5210 - val_root_mean_squared_error: 82.6833\n",
      "Epoch 20/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7214.9593 - root_mean_squared_error: 84.9373 - val_loss: 6838.4683 - val_root_mean_squared_error: 82.6950\n",
      "Epoch 21/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7199.0503 - root_mean_squared_error: 84.8337 - val_loss: 6836.8594 - val_root_mean_squared_error: 82.6853\n",
      "Epoch 22/30\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 7240.2136 - root_mean_squared_error: 85.0854 - val_loss: 6837.8882 - val_root_mean_squared_error: 82.6915\n",
      "Epoch 23/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7293.4340 - root_mean_squared_error: 85.3870 - val_loss: 6838.0210 - val_root_mean_squared_error: 82.6923\n",
      "Epoch 24/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7330.4346 - root_mean_squared_error: 85.6081 - val_loss: 6841.6401 - val_root_mean_squared_error: 82.7142\n",
      "Epoch 25/30\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 7373.5090 - root_mean_squared_error: 85.8541 - val_loss: 6839.0610 - val_root_mean_squared_error: 82.6986\n",
      "Epoch 26/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6960.9376 - root_mean_squared_error: 83.4139 - val_loss: 6839.2119 - val_root_mean_squared_error: 82.6995\n",
      "Epoch 27/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7102.1836 - root_mean_squared_error: 84.2662 - val_loss: 6841.2549 - val_root_mean_squared_error: 82.7119\n",
      "Epoch 28/30\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 6975.9756 - root_mean_squared_error: 83.5061 - val_loss: 6842.6802 - val_root_mean_squared_error: 82.7205\n",
      "Epoch 29/30\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 7167.6751 - root_mean_squared_error: 84.6386 - val_loss: 6841.1753 - val_root_mean_squared_error: 82.7114\n",
      "Epoch 30/30\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6915.2891 - root_mean_squared_error: 83.1150 - val_loss: 6841.2471 - val_root_mean_squared_error: 82.7118\n",
      "98.68599700927734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.08\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# Split the original training set into a reduced training set and a\n",
    "# validation set. \n",
    "validation_split = 0.4\n",
    "\n",
    "# Identify the feature and the label.\n",
    "my_feature = \"median_income\"    # the median income on a specific city block.\n",
    "my_label = \"median_house_value\" # the median house value on a specific city block.\n",
    "# That is, you're going to create a model that predicts house value based \n",
    "# solely on the neighborhood's median income.  \n",
    "\n",
    "# Discard any pre-existing version of the model.\n",
    "my_model = None\n",
    "\n",
    "# Invoke the functions to build and train the model.\n",
    "my_model = build_model(learning_rate)\n",
    "epochs, rmse, history = train_model(my_model, train_df, my_feature, \n",
    "                                    my_label, epochs, batch_size, \n",
    "                                    validation_split)\n",
    "\n",
    "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
    "                    history[\"val_root_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5910d0c",
   "metadata": {},
   "source": [
    "## Task 2: Determine **why** the loss curves differ\n",
    "\n",
    "No matter how you split the training set and the validation set, the loss curves differ significantly. Evidently, the data in the training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is actually pretty common in machine learning. \n",
    "\n",
    "Your task is to determine **why** the loss curves aren't highly similar. As with most issues in machine learning, the problem is rooted in the data itself. To solve this mystery of why the training set and validation set aren't almost identical, write a line or two of [pandas code](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=validation-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en) in the following code cell.  Here are a couple of hints:\n",
    "\n",
    "  * The previous code cell split the original training set into:\n",
    "    * a reduced training set (the original training set - the validation set)\n",
    "    * the validation set \n",
    "  * By default, the pandas [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method outputs the *first* 5 rows of the DataFrame. To see more of the training set, specify the `n` argument to `head` and assign a large positive integer to `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebaa9877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1841.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>82.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3741.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2434.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>48.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>33.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>32.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>33.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>33.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-114.7</td>\n",
       "      <td>33.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-114.9</td>\n",
       "      <td>34.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-115.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-115.2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>3424.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>53.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-115.3</td>\n",
       "      <td>32.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>71.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>74.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>146.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>113.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>32.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>95.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-115.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>107.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>88.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3414.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>91.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>102.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>84.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>70.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>142.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>75.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>63.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2872.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>2644.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>72.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>53.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>60.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>2807.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>67.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>34.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>2082.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>62.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2231.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>60.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>59.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-115.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>84.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2164.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>107.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2511.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>76.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>140.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>62.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2276.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>93.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>97.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>33.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>71.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>64.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>110.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-115.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>90.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0      -114.3      34.2                15.0       5612.0          1283.0   \n",
       "1      -114.5      34.4                19.0       7650.0          1901.0   \n",
       "2      -114.6      33.7                17.0        720.0           174.0   \n",
       "3      -114.6      33.6                14.0       1501.0           337.0   \n",
       "4      -114.6      33.6                20.0       1454.0           326.0   \n",
       "5      -114.6      33.6                29.0       1387.0           236.0   \n",
       "6      -114.6      33.6                25.0       2907.0           680.0   \n",
       "7      -114.6      34.8                41.0        812.0           168.0   \n",
       "8      -114.6      33.6                34.0       4789.0          1175.0   \n",
       "9      -114.6      34.8                46.0       1497.0           309.0   \n",
       "10     -114.6      33.6                16.0       3741.0           801.0   \n",
       "11     -114.6      33.6                21.0       1988.0           483.0   \n",
       "12     -114.6      34.8                48.0       1291.0           248.0   \n",
       "13     -114.6      34.8                31.0       2478.0           464.0   \n",
       "14     -114.6      32.8                15.0       1448.0           378.0   \n",
       "15     -114.7      34.9                17.0       2556.0           587.0   \n",
       "16     -114.7      33.6                28.0       1678.0           322.0   \n",
       "17     -114.7      32.8                21.0         44.0            33.0   \n",
       "18     -114.7      32.7                17.0       1388.0           386.0   \n",
       "19     -114.7      33.9                17.0         97.0            24.0   \n",
       "20     -114.7      33.5                20.0       1491.0           360.0   \n",
       "21     -114.7      33.4                24.0        796.0           243.0   \n",
       "22     -114.9      34.5                20.0        350.0            95.0   \n",
       "23     -115.0      33.8                15.0        644.0           129.0   \n",
       "24     -115.2      33.5                18.0       1706.0           397.0   \n",
       "25     -115.3      32.8                34.0        591.0           139.0   \n",
       "26     -115.4      32.8                30.0       1602.0           322.0   \n",
       "27     -115.4      32.8                14.0       1276.0           270.0   \n",
       "28     -115.4      32.8                32.0        741.0           191.0   \n",
       "29     -115.4      32.8                23.0       1458.0           294.0   \n",
       "30     -115.4      32.8                38.0       1892.0           394.0   \n",
       "31     -115.4      32.8                35.0       1263.0           262.0   \n",
       "32     -115.4      32.8                16.0       1136.0           196.0   \n",
       "33     -115.4      32.9                19.0       1087.0           171.0   \n",
       "34     -115.4      32.7                19.0        583.0           113.0   \n",
       "35     -115.4      33.0                29.0       1141.0           220.0   \n",
       "36     -115.5      33.2                33.0       1234.0           373.0   \n",
       "37     -115.5      32.8                21.0       1260.0           246.0   \n",
       "38     -115.5      32.7                15.0       3414.0           666.0   \n",
       "39     -115.5      32.9                19.0        541.0           104.0   \n",
       "40     -115.5      32.7                17.0       1960.0           389.0   \n",
       "41     -115.5      32.7                29.0       1523.0           440.0   \n",
       "42     -115.5      32.7                25.0       2322.0           573.0   \n",
       "43     -115.5      32.8                13.0        330.0            72.0   \n",
       "44     -115.5      32.7                18.0       3631.0           913.0   \n",
       "45     -115.5      32.7                35.0       2159.0           492.0   \n",
       "46     -115.5      33.2                32.0       1995.0           523.0   \n",
       "47     -115.5      33.1                21.0       1024.0           218.0   \n",
       "48     -115.5      33.0                20.0       1402.0           287.0   \n",
       "49     -115.5      32.7                11.0       2872.0           610.0   \n",
       "50     -115.5      34.2                30.0        540.0           136.0   \n",
       "51     -115.5      33.1                18.0       1109.0           283.0   \n",
       "52     -115.5      33.1                38.0       1327.0           262.0   \n",
       "53     -115.5      33.0                32.0       1615.0           382.0   \n",
       "54     -115.5      33.0                24.0       1617.0           366.0   \n",
       "55     -115.5      33.0                10.0       1879.0           387.0   \n",
       "56     -115.5      32.8                18.0       1715.0           337.0   \n",
       "57     -115.5      32.7                17.0       1190.0           275.0   \n",
       "58     -115.5      32.7                 6.0       2804.0           581.0   \n",
       "59     -115.5      34.9                12.0        807.0           199.0   \n",
       "60     -115.5      33.0                25.0       2578.0           634.0   \n",
       "61     -115.5      33.0                35.0       1583.0           340.0   \n",
       "62     -115.5      33.0                34.0       2231.0           545.0   \n",
       "63     -115.5      32.7                14.0       1527.0           325.0   \n",
       "64     -115.5      33.0                23.0       1459.0           373.0   \n",
       "65     -115.5      33.0                17.0       1697.0           268.0   \n",
       "66     -115.5      33.0                27.0       1513.0           395.0   \n",
       "67     -115.5      33.0                41.0       2429.0           454.0   \n",
       "68     -115.5      32.8                23.0       1712.0           403.0   \n",
       "69     -115.5      33.0                33.0       2266.0           365.0   \n",
       "70     -115.5      33.0                24.0       2565.0           530.0   \n",
       "71     -115.5      32.8                34.0       1540.0           316.0   \n",
       "72     -115.5      32.8                23.0        666.0           142.0   \n",
       "73     -115.5      32.8                23.0       1004.0           221.0   \n",
       "74     -115.5      32.8                22.0        565.0           162.0   \n",
       "75     -115.5      32.8                 5.0       2652.0           606.0   \n",
       "76     -115.6      33.0                21.0       2164.0           480.0   \n",
       "77     -115.6      32.8                28.0       1672.0           416.0   \n",
       "78     -115.6      32.8                25.0       1311.0           375.0   \n",
       "79     -115.6      32.8                15.0       1171.0           328.0   \n",
       "80     -115.6      32.8                20.0       2372.0           835.0   \n",
       "81     -115.6      32.8                18.0       1178.0           438.0   \n",
       "82     -115.6      32.8                46.0       2511.0           490.0   \n",
       "83     -115.6      32.8                35.0       1185.0           202.0   \n",
       "84     -115.6      32.8                29.0       1568.0           283.0   \n",
       "85     -115.6      32.8                15.0       1278.0           217.0   \n",
       "86     -115.6      32.9                33.0       1365.0           269.0   \n",
       "87     -115.6      32.9                17.0       1039.0           256.0   \n",
       "88     -115.6      32.8                29.0       1207.0           301.0   \n",
       "89     -115.6      32.8                31.0       1494.0           289.0   \n",
       "90     -115.6      32.8                16.0       2276.0           594.0   \n",
       "91     -115.6      32.8                34.0       1152.0           208.0   \n",
       "92     -115.6      32.8                20.0       1534.0           235.0   \n",
       "93     -115.6      32.8                15.0       1413.0           279.0   \n",
       "94     -115.6      33.9                21.0       1161.0           282.0   \n",
       "95     -115.6      32.8                 5.0        805.0           143.0   \n",
       "96     -115.6      32.8                10.0       1088.0           203.0   \n",
       "97     -115.6      32.8                14.0       1687.0           507.0   \n",
       "98     -115.6      32.8                 5.0       2494.0           414.0   \n",
       "99     -115.6      32.9                20.0       1608.0           274.0   \n",
       "\n",
       "    population  households  median_income  median_house_value  \n",
       "0       1015.0       472.0            1.5                66.9  \n",
       "1       1129.0       463.0            1.8                80.1  \n",
       "2        333.0       117.0            1.7                85.7  \n",
       "3        515.0       226.0            3.2                73.4  \n",
       "4        624.0       262.0            1.9                65.5  \n",
       "5        671.0       239.0            3.3                74.0  \n",
       "6       1841.0       633.0            2.7                82.4  \n",
       "7        375.0       158.0            1.7                48.5  \n",
       "8       3134.0      1056.0            2.2                58.4  \n",
       "9        787.0       271.0            2.2                48.1  \n",
       "10      2434.0       824.0            2.7                86.5  \n",
       "11      1182.0       437.0            1.6                62.0  \n",
       "12       580.0       211.0            2.2                48.6  \n",
       "13      1346.0       479.0            3.2                70.4  \n",
       "14       949.0       300.0            0.9                45.0  \n",
       "15      1005.0       401.0            1.7                69.1  \n",
       "16       666.0       256.0            3.0                94.9  \n",
       "17        64.0        27.0            0.9                25.0  \n",
       "18       775.0       320.0            1.2                44.0  \n",
       "19        29.0        15.0            1.3                27.5  \n",
       "20      1135.0       303.0            1.6                44.4  \n",
       "21       227.0       139.0            0.9                59.2  \n",
       "22       119.0        58.0            1.6                50.0  \n",
       "23       137.0        52.0            3.2                71.3  \n",
       "24      3424.0       283.0            1.6                53.5  \n",
       "25       327.0        89.0            3.7               100.0  \n",
       "26      1130.0       335.0            3.6                71.1  \n",
       "27       867.0       261.0            1.9                80.9  \n",
       "28       623.0       169.0            1.8                68.6  \n",
       "29       866.0       275.0            2.4                74.3  \n",
       "30      1175.0       374.0            2.0                65.8  \n",
       "31       950.0       241.0            1.9                67.5  \n",
       "32       481.0       185.0            6.3               146.3  \n",
       "33       649.0       173.0            3.3               113.8  \n",
       "34       531.0       134.0            1.7                95.8  \n",
       "35       684.0       194.0            3.4               107.8  \n",
       "36       777.0       298.0            1.0                40.0  \n",
       "37       805.0       239.0            2.6                88.5  \n",
       "38      2097.0       622.0            2.3                91.2  \n",
       "39       457.0       106.0            3.4               102.8  \n",
       "40      1691.0       356.0            1.9                64.0  \n",
       "41      1302.0       393.0            1.1                84.7  \n",
       "42      2185.0       602.0            1.4                70.1  \n",
       "43       822.0        64.0            3.4               142.5  \n",
       "44      3565.0       924.0            1.6                88.4  \n",
       "45      1694.0       475.0            2.2                75.5  \n",
       "46      1069.0       410.0            1.7                43.3  \n",
       "47       890.0       232.0            2.1                46.7  \n",
       "48      1104.0       317.0            1.9                63.7  \n",
       "49      2644.0       581.0            2.6                72.7  \n",
       "50       122.0        63.0            1.3                42.5  \n",
       "51      1006.0       253.0            2.2                53.4  \n",
       "52       784.0       231.0            1.9                60.8  \n",
       "53      1307.0       345.0            1.5                58.6  \n",
       "54      1416.0       401.0            2.0                66.4  \n",
       "55      1376.0       337.0            2.0                67.5  \n",
       "56      1166.0       333.0            2.2                79.2  \n",
       "57      1113.0       258.0            2.4                63.1  \n",
       "58      2807.0       594.0            2.1                67.7  \n",
       "59       246.0       102.0            2.5                40.0  \n",
       "60      2082.0       565.0            1.7                62.2  \n",
       "61       933.0       318.0            2.4                70.7  \n",
       "62      1568.0       510.0            1.5                60.3  \n",
       "63      1453.0       332.0            1.7                61.2  \n",
       "64      1148.0       388.0            1.5                69.4  \n",
       "65       911.0       254.0            4.4                96.0  \n",
       "66      1121.0       381.0            1.9                60.6  \n",
       "67      1188.0       430.0            3.0                70.8  \n",
       "68      1370.0       377.0            1.3                60.4  \n",
       "69       952.0       360.0            5.4               143.0  \n",
       "70      1447.0       473.0            3.3                80.8  \n",
       "71      1013.0       274.0            2.6                67.5  \n",
       "72       580.0       160.0            2.1                61.0  \n",
       "73       697.0       201.0            1.6                59.6  \n",
       "74       692.0       141.0            1.2                53.6  \n",
       "75      1767.0       536.0            2.8                84.3  \n",
       "76      1164.0       421.0            3.8               107.2  \n",
       "77      1335.0       397.0            1.6                59.4  \n",
       "78      1193.0       351.0            2.2                63.9  \n",
       "79      1024.0       298.0            1.4                69.4  \n",
       "80      2283.0       767.0            1.2                62.5  \n",
       "81      1377.0       429.0            1.3                58.3  \n",
       "82      1583.0       469.0            3.1                70.8  \n",
       "83       615.0       191.0            4.6                86.2  \n",
       "84       848.0       245.0            3.2                76.2  \n",
       "85       653.0       185.0            4.5               140.3  \n",
       "86       825.0       250.0            3.2                62.3  \n",
       "87       728.0       246.0            1.7                63.5  \n",
       "88       804.0       288.0            2.0                61.1  \n",
       "89       959.0       284.0            3.5                67.5  \n",
       "90      1184.0       513.0            1.9                93.8  \n",
       "91       621.0       208.0            3.6                73.6  \n",
       "92       871.0       222.0            6.3                97.2  \n",
       "93       803.0       277.0            4.3                87.5  \n",
       "94       724.0       186.0            3.2                71.7  \n",
       "95       458.0       143.0            4.5                96.3  \n",
       "96       533.0       201.0            3.7                87.5  \n",
       "97       762.0       451.0            1.7                64.4  \n",
       "98      1416.0       421.0            5.8               110.1  \n",
       "99       862.0       248.0            4.9                90.8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_rows', 100)\n",
    "train_df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Double-click for a possible solution to Task 2.\n",
    "\n",
    "# Examine examples 0 through 4 and examples 25 through 29\n",
    "# of the training set\n",
    "train_df.head(n=1000)\n",
    "\n",
    "# The original training set is sorted by longitude. \n",
    "# Apparently, longitude influences the relationship of\n",
    "# total_rooms to median_house_value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909a5ac",
   "metadata": {},
   "source": [
    "## Task 3. Fix the problem\n",
    "\n",
    "To fix the problem, shuffle the examples in the training set before splitting the examples into a training set and validation set. To do so, take the following steps:\n",
    "\n",
    "1. Shuffle the data in the training set by adding the following line anywhere before you call `train_model` (in the code cell associated with Task 1):\n",
    "\n",
    "```\n",
    "  shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
    "```                                    \n",
    "\n",
    "2. Pass `shuffled_train_df` (instead of `train_df`) as the second argument to `train_model` (in the code call associated with Task 1) so that the call becomes as follows:\n",
    "\n",
    "```\n",
    "  epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
    "                                      my_label, epochs, batch_size, \n",
    "                                      validation_split)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f250e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c13791ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 50326.6540 - root_mean_squared_error: 224.2456 - val_loss: 34807.5820 - val_root_mean_squared_error: 186.5679\n",
      "Epoch 2/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 31127.1087 - root_mean_squared_error: 176.2848 - val_loss: 20262.2793 - val_root_mean_squared_error: 142.3456\n",
      "Epoch 3/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 17446.1738 - root_mean_squared_error: 132.0146 - val_loss: 11168.6895 - val_root_mean_squared_error: 105.6820\n",
      "Epoch 4/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 10070.9518 - root_mean_squared_error: 100.2619 - val_loss: 7317.9946 - val_root_mean_squared_error: 85.5453\n",
      "Epoch 5/30\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 7183.9537 - root_mean_squared_error: 84.7470 - val_loss: 6992.9590 - val_root_mean_squared_error: 83.6239\n",
      "Epoch 6/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 6898.5835 - root_mean_squared_error: 83.0513 - val_loss: 6998.5557 - val_root_mean_squared_error: 83.6574\n",
      "Epoch 7/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 6911.8816 - root_mean_squared_error: 83.1148 - val_loss: 6994.2432 - val_root_mean_squared_error: 83.6316\n",
      "Epoch 8/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6951.9518 - root_mean_squared_error: 83.3754 - val_loss: 6994.1304 - val_root_mean_squared_error: 83.6309\n",
      "Epoch 9/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6961.5245 - root_mean_squared_error: 83.4320 - val_loss: 6992.9927 - val_root_mean_squared_error: 83.6241\n",
      "Epoch 10/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6973.7315 - root_mean_squared_error: 83.5000 - val_loss: 6992.9282 - val_root_mean_squared_error: 83.6237\n",
      "Epoch 11/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6832.0677 - root_mean_squared_error: 82.6432 - val_loss: 6993.7983 - val_root_mean_squared_error: 83.6289\n",
      "Epoch 12/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6877.6774 - root_mean_squared_error: 82.9268 - val_loss: 6994.3125 - val_root_mean_squared_error: 83.6320\n",
      "Epoch 13/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7035.6291 - root_mean_squared_error: 83.8713 - val_loss: 6992.7622 - val_root_mean_squared_error: 83.6227\n",
      "Epoch 14/30\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 6996.2438 - root_mean_squared_error: 83.6371 - val_loss: 6992.9961 - val_root_mean_squared_error: 83.6241\n",
      "Epoch 15/30\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 6981.2714 - root_mean_squared_error: 83.5528 - val_loss: 6993.0103 - val_root_mean_squared_error: 83.6242\n",
      "Epoch 16/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 7062.9335 - root_mean_squared_error: 84.0314 - val_loss: 6995.0400 - val_root_mean_squared_error: 83.6364\n",
      "Epoch 17/30\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 7206.8734 - root_mean_squared_error: 84.8642 - val_loss: 6992.9155 - val_root_mean_squared_error: 83.6237\n",
      "Epoch 18/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7088.1201 - root_mean_squared_error: 84.1848 - val_loss: 6993.1577 - val_root_mean_squared_error: 83.6251\n",
      "Epoch 19/30\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 7069.0319 - root_mean_squared_error: 84.0632 - val_loss: 6994.2310 - val_root_mean_squared_error: 83.6315\n",
      "Epoch 20/30\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 6995.6831 - root_mean_squared_error: 83.6361 - val_loss: 6997.1479 - val_root_mean_squared_error: 83.6490\n",
      "Epoch 21/30\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 7284.0047 - root_mean_squared_error: 85.3232 - val_loss: 6993.6245 - val_root_mean_squared_error: 83.6279\n",
      "Epoch 22/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7285.0675 - root_mean_squared_error: 85.3296 - val_loss: 6992.7769 - val_root_mean_squared_error: 83.6228\n",
      "Epoch 23/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 6851.6483 - root_mean_squared_error: 82.7698 - val_loss: 6993.4180 - val_root_mean_squared_error: 83.6267\n",
      "Epoch 24/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 7049.1789 - root_mean_squared_error: 83.9511 - val_loss: 6992.8687 - val_root_mean_squared_error: 83.6234\n",
      "Epoch 25/30\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 6983.2766 - root_mean_squared_error: 83.5471 - val_loss: 6993.8525 - val_root_mean_squared_error: 83.6293\n",
      "Epoch 26/30\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 6973.1712 - root_mean_squared_error: 83.4978 - val_loss: 6994.6724 - val_root_mean_squared_error: 83.6342\n",
      "Epoch 27/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6898.3150 - root_mean_squared_error: 83.0522 - val_loss: 6992.6895 - val_root_mean_squared_error: 83.6223\n",
      "Epoch 28/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6910.6782 - root_mean_squared_error: 83.1241 - val_loss: 6993.5146 - val_root_mean_squared_error: 83.6272\n",
      "Epoch 29/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7187.5897 - root_mean_squared_error: 84.7687 - val_loss: 6993.3936 - val_root_mean_squared_error: 83.6265\n",
      "Epoch 30/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7025.8471 - root_mean_squared_error: 83.8115 - val_loss: 6992.8149 - val_root_mean_squared_error: 83.6231\n",
      "82.66526794433594\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAArAElEQVR4nO3de3xcdZ3/8dcnSZukSXOhSUlokjYBCvbeEtrdgtpyURZZQC5Cf7BScBERQfGnsrquoPy68mNZ9IGK+wMFvCDdooLgIrcqVEWBthRsuZa20NB7S9v03iSf3x/nJJ1kJsk0ycxkZt7Px2OYM98zc+ZzclI++Z7vzdwdERGRSDmpDkBERAYfJQcREYmi5CAiIlGUHEREJIqSg4iIRMlLdQD9UVFR4WPGjEl1GCIiaWXJkiVb3L2yp/ekdXIYM2YMixcvTnUYIiJpxcze6e09uq0kIiJRlBxERCSKkoOIiERJ6zYHEUmegwcP0tTUxL59+1IdisSpoKCAmpoahgwZctifVXIQkbg0NTUxfPhwxowZg5mlOhzphbuzdetWmpqaqK+vP+zP67aSiMRl3759jBgxQokhTZgZI0aM6HNNT8lBROKmxJBe+nO9sjI5vLd9L7c/+QbvbN2d6lBERAalrEwO2/cc4I7fr+TVdTtTHYqIxGHr1q1MmTKFKVOmUFVVxahRozpeHzhwoMfPLl68mOuuu67X75g5c+aAxPrMM89w1llnDcixUikrG6SrSwsBWL9DvS5E0sGIESNYtmwZADfddBPFxcV86Utf6tjf0tJCXl7s/501NjbS2NjY63c899xzAxJrpsjKmkP5sCEMzcthw04lB5F0NXfuXL74xS8ye/ZsbrjhBl544QVmzpzJ1KlTmTlzJm+88QbQ+S/5m266iSuuuIJZs2bR0NDAHXfc0XG84uLijvfPmjWLCy64gOOPP55LLrmE9hUzH3vsMY4//nhOPvlkrrvuusOqITzwwANMnDiRCRMmcMMNNwDQ2trK3LlzmTBhAhMnTuQ73/kOAHfccQfjxo1j0qRJXHzxxf3/YfVBVtYczIzq0gLVHET66JuPrhjw27Ljjirhxn8cf1ifefPNN3n66afJzc1l586dLFq0iLy8PJ5++mm+9rWv8atf/SrqM6+//jp/+MMfaG5u5rjjjuPqq6+OGgfw0ksvsWLFCo466ihOOukk/vznP9PY2MhVV13FokWLqK+vZ86cOXHHuW7dOm644QaWLFlCeXk5H/nIR3j44Yepra3lvffeY/ny5QBs374dgFtuuYXVq1eTn5/fUZZsWVlzAKgqKWDDjr2pDkNE+uHCCy8kNzcXgB07dnDhhRcyYcIErr/+elasWBHzMx/72MfIz8+noqKCkSNHsnHjxqj3TJ8+nZqaGnJycpgyZQpr1qzh9ddfp6GhoWPMwOEkhxdffJFZs2ZRWVlJXl4el1xyCYsWLaKhoYFVq1Zx7bXX8vjjj1NSUgLApEmTuOSSS/j5z3/e7e2yRMvKmgNAdWkBi995P9VhiKSlw/0LP1GKioo6tv/t3/6N2bNn89BDD7FmzRpmzZoV8zP5+fkd27m5ubS0tMT1nvZbS33R3WfLy8t5+eWXeeKJJ/jBD37AggULuOeee/if//kfFi1axCOPPMLNN9/MihUrkp4ksrfmUFrIxp37aGvr+wUXkcFjx44djBo1CoD77rtvwI9//PHHs2rVKtasWQPAf//3f8f92RkzZvDss8+yZcsWWltbeeCBB/jwhz/Mli1baGtr4/zzz+fmm29m6dKltLW1sXbtWmbPns2tt97K9u3b2bVr14CfT2+yuuZwsNXZuvsAlcPze/+AiAxqX/nKV7jsssu4/fbbOeWUUwb8+IWFhdx5552cccYZVFRUMH369G7fu3DhQmpqajpeP/jgg3z7299m9uzZuDtnnnkm55xzDi+//DKXX345bW1tAHz729+mtbWVSy+9lB07duDuXH/99ZSVlQ34+fTG+lNVSrXGxkbv62I/T6zYwFU/W8KjnzuZiTWlAxyZSOZ57bXX+MAHPpDqMFJq165dFBcX4+5cc801HHvssVx//fWpDqtHsa6bmS1x9x7792btbaXq0gIA1qtRWkTidPfddzNlyhTGjx/Pjh07uOqqq1IdUsJk7W2lqjA5aKyDiMTr+uuvH/Q1hYGStTWHiqJ88nJMYx1ERGJIWHIws3vMbJOZLe9Sfq2ZvWFmK8zs1ojyr5rZynDfRxMVV7ucHOPIkgI2KDmIiERJ5G2l+4DvAz9tLzCz2cA5wCR3329mI8PyccDFwHjgKOBpMxvr7q0JjC8cJa02BxGRrhJWc3D3RcC2LsVXA7e4+/7wPZvC8nOA+e6+391XAyuB7vuJDZCqUtUcRERiSXabw1jgg2b2vJk9a2YnhuWjgLUR72sKy6KY2afNbLGZLd68eXO/gmmfXymdu/OKZINZs2bxxBNPdCr77ne/y2c/+9keP9Pe1f3MM8+MOUfRTTfdxG233dbjdz/88MO8+uqrHa+/8Y1v8PTTTx9G9LEN9qm9k50c8oBy4O+ALwMLLFiqKNZyRTH/j+3ud7l7o7s3VlZW9iuYqtJC9re0sX3PwX4dR0QSa86cOcyfP79T2fz58+Oe3+ixxx7r80CyrsnhW9/6FqeddlqfjpVOkp0cmoBfe+AFoA2oCMtrI95XA6xLdDCHxjro1pLIYHbBBRfw29/+lv379wOwZs0a1q1bx8knn8zVV19NY2Mj48eP58Ybb4z5+TFjxrBlyxYA5s2bx3HHHcdpp53WMa03BGMYTjzxRCZPnsz555/Pnj17eO6553jkkUf48pe/zJQpU3j77beZO3cuv/zlL4FgJPTUqVOZOHEiV1xxRUd8Y8aM4cYbb2TatGlMnDiR119/Pe5zHSxTeyd7nMPDwCnAM2Y2FhgKbAEeAX5hZrcTNEgfC7yQ6GAOjXXYy7ijShL9dSKZ43f/Ahv+NrDHrJoI/3BLzF0jRoxg+vTpPP7445xzzjnMnz+fiy66CDNj3rx5HHHEEbS2tnLqqafyyiuvMGnSpJjHWbJkCfPnz+ell16ipaWFadOmccIJJwBw3nnnceWVVwLw9a9/nR//+Mdce+21nH322Zx11llccMEFnY61b98+5s6dy8KFCxk7diyf/OQn+eEPf8gXvvAFACoqKli6dCl33nknt912Gz/60Y96/REMpqm9E9mV9QHgL8BxZtZkZp8C7gEawu6t84HLwlrECmAB8CrwOHBNonsqgWoOIukk8tZS5C2lBQsWMG3aNKZOncqKFSs63QLq6o9//CMf//jHGTZsGCUlJZx99tkd+5YvX84HP/hBJk6cyP3339/tlN/t3njjDerr6xk7diwAl112GYsWLerYf9555wFwwgkndEzW15vBNLV3wmoO7t7dzcBLu3n/PGBeouKJpbI4nxxDPZZEDlc3f+En0rnnnssXv/hFli5dyt69e5k2bRqrV6/mtttu48UXX6S8vJy5c+eyb1/P/56DZs5oc+fO5eGHH2by5Mncd999PPPMMz0ep7eOLO3Tfnc3LfjhHDMVU3tn7QhpgLzcHEYO14pwIumguLiYWbNmccUVV3TUGnbu3ElRURGlpaVs3LiR3/3udz0e40Mf+hAPPfQQe/fupbm5mUcffbRjX3NzM9XV1Rw8eJD777+/o3z48OE0NzdHHev4449nzZo1rFy5EoCf/exnfPjDH+7XOQ6mqb2zdm6ldhrrIJI+5syZw3nnnddxe2ny5MlMnTqV8ePH09DQwEknndTj56dNm8ZFF13ElClTGD16NB/84Ac79t18883MmDGD0aNHM3HixI6EcPHFF3PllVdyxx13dDREAxQUFHDvvfdy4YUX0tLSwoknnshnPvOZwzqfwTy1d9ZO2d3u6p8v4c2NzSz837MGJiiRDKUpu9OTpuzuoyoNhBMRiZL1yaG6tIA9B1pp3h9fg5GISDbI+uRQVVoIqMeSSDxUw04v/bleWZ8cNNZBJD4FBQVs3bpVCSJNuDtbt26loKCgT59Xb6WScJS0pu4W6VFNTQ1NTU30d8JLSZ6CgoJOvaEOR9YnhyNLVHMQiceQIUOor69PdRiSJFl/W2loXg4VxflqcxARiZD1yQEOresgIiIBJQc0SlpEpCslB7SWtIhIV0oOBDWHnfta2K2BcCIigJIDcGisw4adurUkIgJKDgBUlWiUtIhIJCUHNEpaRKSrHpODmeWa2X8kK5hU6VhLWo3SIiJAL8khXMf5BOtuXb0MUTAkl/JhQ1RzEBEJxTN9xkvAb8zsQWB3e6G7/zphUaVAVWmh2hxERELxJIcjgK3AKRFlDmRUctAoaRGRQ3pNDu5+eTICSbWq0gKWrd2e6jBERAaFXnsrmVmNmT1kZpvMbKOZ/crM+jYH7CBWXVLAtt0H2HewNdWhiIikXDxdWe8FHgGOAkYBj4ZlGaW9x9JGDYQTEYkrOVS6+73u3hI+7gMqExxX0lWHy4Wq3UFEJL7ksMXMLg3HPOSa2aUEDdQZ5dBYByUHEZF4ksMVwCeADcB64IKwLKNUaZS0iEiHHnsrmVku8O/ufnaS4kmZ4vw8hhfkaZS0iAjxjZCuNLOhSYonpTTWQUQkEM8guDXAn83sETqPkL49UUGlSlVpoabtFhEhvuSwLnzkAMMTG05qVZcU8Nr6nakOQ0Qk5eJpczjW3S9NUjwpVVVawJZd+znQ0sbQPM1mLiLZS20OEapLC3CHTc26tSQi2U1tDhEixzrUlA9LcTQiIqmjNocIGiUtIhKIZ1bWb3YtM7N4ksrgtb8Z3lsKVRNh2BEdxRolLSIS6LbNwcz+FLH9sy67X0hYRMmw+Q346dmwtvNplBTkMWxormoOIpL1emqQLorYntBlX3ovG1pWFzxvf7dTsZlRVVrAhp0aJS0i2a2n5ODdbMd6nV6KKiGvALa/E7WrurRAt5VEJOv1lBzKzOzjZnZ+uH1e+DgfKO3twGZ2T7hA0PIY+75kZm5mFRFlXzWzlWb2hpl9tE9nEy8zKK2NqjkAVJVoLWkRkZ4alp8Fzo7Y/seIfYviOPZ9wPeBn0YWmlktcDrwbkTZOOBiYDzBokJPm9nYcJxFYpTVwY61UcXVpQVsbN5Pa5uTm5Ped89ERPqq2+TQ37Wj3X2RmY2Jses7wFeA30SUnQPMd/f9wGozWwlMB/7Snxh6VFYH65dFFVeVFtDa5mzZtZ8jSwoS9vUiIoNZUueIMLOzgffc/eUuu0YBkX/GN4VlsY7xaTNbbGaLN2/e3Pdgyupgz1bYv6tTcbXWdRARSV5yMLNhwL8C34i1O0ZZzEZvd7/L3RvdvbGysh+rlbb3WOpya+nQWAf1WBKR7JXMmsPRQD3wspmtAWqApWZWRVBTqI14bw3BqOzE6ejO2jk5aJS0iEgPbQ5mdl5PH3T3Xx/OF7n734CREcdfAzS6+5Zw3qZfmNntBA3Sx5LogXYdyaFzd9byYUMYmpejHksiktV66q3U3jtpJDAT+H34ejbwDNBjcjCzB4BZQIWZNQE3uvuPY73X3VeY2QLgVaAFuCahPZUAikZCbn7MgXBaEU5Esl2vvZXM7LfAOHdfH76uBn7Q24HdfU4v+8d0eT0PmNd7yAMkJwdKa7oZ66CBcCKS3eJpcxjTnhhCG4GxCYonuXoY67BeU2iISBaLZ3bVZ8zsCeABgh5EFwN/SGhUyVJWB288FlVcVVrIxh0baGtzcjQQTkSyUDxTdn/OzD4OfCgsusvdH0psWElSVge7N8OBPTD00OI+1aUFHGhtY9ueA1QU56cwQBGR1Ih3XYalQLO7P21mw8xsuLs3JzKwpOgY69AElYfulEWu66DkICLZqNc2BzO7Evgl8P/ColHAwwmMKXm6mbpbo6RFJNvF0yB9DXASsBPA3d8iYrxCWutmrINGSYtItosnOex39wPtL8IlQtN7PYd2xVWQMySq5lBRlE9ejqnmICJZK57k8KyZfQ0oNLPTgQeBRxMbVpK0j3Xo0p01J8c4UmMdRCSLxZMcbgA2A38DrgIeA76eyKCSqqwu5kA4jZIWkWzWY28lM8sBXnH3CcDdyQkpycrq4K0no4qrSgtYsW5nCgISEUm9HmsO7t5GMItqXZLiSb6yOti1EQ52riUENYe9uGdG84qIyOGIZ5xDNbDCzF4AdrcXuvvZ3X8kjUSOdag4pqO4qrSQfQfb2LH3IGXDhqYoOBGR1IgnOXwz4VGkUmR31ojkEDnWQclBRLJNPNNnPJuMQFKmm4FwkaOkP1BdkuyoRERSKp4R0n9nZi+a2S4zO2BmrWaWOS21w6shJ0+jpEVEIsTTlfX7wBzgLaAQ+OewLDPk5ELJqKixDpXF+eSYRkmLSHaKa+I9d19pZrnh6mz3mtlzCY4ruWKMdcjLzWHkcI11EJHsFE9y2GNmQ4FlZnYrsB4oSmxYSVY2Gt5eGFVcVVrAhp1KDiKSfeK5rfRPQC7wOYKurLXA+YkMKunKaqF5PbTs71SsUdIikq3i6a3UPmXpXjK1W2vkWIcRR3cUV5UW8Me3tqQoKBGR1Ok1OZjZamLMwuruDQmJKBUiu7NGJIfq0gJ27W+hed9BhhcMSVFwIiLJF0+bQ2PEdgFwIXBEYsJJkW7HOhQCwVgHJQcRySa9tjm4+9aIx3vu/l3glMSHlkTDjwLLjerOqrEOIpKt4rmtNC3iZQ5BTWJ4wiJKhdy8YKxD15pDyaFR0iIi2SSe20r/GbHdAqwBPpGQaFIpxliHI0tUcxCR7BRPb6XZyQgk5cpqYfWiTkVD83KoKM5nw06NkhaR7BLPbaUv9rTf3W8fuHBSqKwuHOtwAPIOzcKqsQ4iko3iGQTXCFwNjAofnwHGEbQ7ZE7bQ1kdeBvsfK9TcVWp1pIWkewTT5tDBTDN3ZsBzOwm4EF3/+dEBpZ0kd1Zj6jvKK4uLeCF1dtSFJSISGrEU3OoAw5EvD4AjElINKlUWhs8x1jXYcfeg+w50JKCoEREUiOemsPPgBfM7KHw9bnATxIWUaqUjALL6Xasw7rt+zhmZHEqIhMRSbp4BsHNAy4H3ge2AZe7+7cTHVjS5Q0NBsN1qTmMHhFMQLtmy+5YnxIRyUjdJgczG2ZmQwDcfSnwOMHsrPXdfSbtxRjr0FARJIfVSg4ikkV6qjk8Tti2YGbHAH8BGoBrzOyWxIeWAmW1UcmhbNhQjigayqotu1IUlIhI8vWUHMrd/a1w+zLgAXe/FvgH4GMJjywVyupg5zpo7dz4XF9RxKrNqjmISPboKTlETtN9CvAUgLsfANoSGVTKlNWBt0aNdWioKGKVbiuJSBbpKTm8Yma3mdn1wDHAkwBmVpaMwFKim6m76yuL2Ny8n+Z9B1MQlIhI8vWUHK4EthC0O3zE3feE5eOA2xIcV2p0M9ahoSLowqpGaRHJFt2Oc3D3vUBUw7O7Pwc8l8igUqa0BrCosQ4NlYd6LE2qKUt+XCIiSRbPCOk+MbN7zGyTmS2PKPsPM3vdzF4xs4cib1GZ2VfNbKWZvWFmH01UXD3Ky4fh1THGOgzDDN5Wo7SIZImEJQfgPuCMLmVPARPcfRLwJvBVADMbB1wMjA8/c6eZ5SYwtu7FGOuQn5dLTXmhbiuJSNZIWHJw90UEI6ojy5509/Z+on8FasLtc4D57r7f3VcDK4HpiYqtRzHGOkDQ7rBqs8Y6iEh26DU5mNlYM7vbzJ40s9+3Pwbgu68AfhdujwIib/Q3hWWx4vm0mS02s8WbN28egDC6KKsLurJ2GevQUFnE6i27cfduPigikjnimXjvQeC/gLuB1oH4UjP7V4IlR+9vL4rxtpj/F3b3u4C7ABobGwf+/9RlddDWEiz8U1bbUdxQUcSeA61s3LmfqnAyPhGRTBVPcmhx9x8O1Bea2WXAWcCpfujP8CagNuJtNcC6gfrOwxLZnTUyOVQG3VlXbd6l5CAiGS+eNodHzeyzZlZtZke0P/ryZWZ2BnADcHbEuAmAR4CLzSzfzOqBY4EX+vId/VY2Onju0p21PpyATyOlRSQbxFNzuCx8/nJEmRNMwtctM3sAmAVUmFkTcCNB76R84CkzA/iru3/G3VeY2QLgVYLbTde4+4DcwjpspWEbeddFf0oKKBySqzmWRCQr9Joc3L1PU3S7+5wYxT/u4f3zgHl9+a4BNaQAiqtg+zudinNyjDEVRazW7KwikgXiqTlgZhMIps3ouNnu7j9NVFAp11131soilr+3IwUBiYgkVzxdWW8Evhc+ZgO3AmcnOK7UKquD7Wujihsqili7bQ8HWjJzUloRkXbxNEhfAJwKbHD3y4HJBO0GmausDnY0QVvnZo+GyiLaHN7dpnYHEcls8SSHve7eBrSYWQmwiV4ao9NeWR20HYTmDZ2K6yvau7MqOYhIZosnOSwOJ8i7G1gCLCVV3UyTpbSbdR3UnVVEskQ8vZU+G27+l5k9DpS4+yuJDSvF2hf92bEW+PuO4tLCIVQUD2W1ag4ikuHiaZA2M7vUzL7h7muA7WaWmknxkqV9ZHSX7qwQTsCn7qwikuHiua10J8Gfz+3jFpqBHyQsosFgSCEUjYzZnbW+okhTd4tIxosnOcxw92uAfQDu/j4wNKFRDQY9jHXYsusAO/ZqPWkRyVzxJIeD4cI7DmBmlUDmd/TvZqxDe6O0ag8iksniSQ53AA8BI81sHvAn4N8TGtVgUFYXNEi3dc6DkbOziohkqnh6K91vZksIBsIZcK67v5bwyFKtrA5aD8CujVBS3VFcd8QwcnNMNQcRyWjdJocu03JvAh6I3Ofu26I/lUFKI7qzRiSHoXk51JYXaiCciGS0nmoOWwgW4WlfLzNytbZep+xOe2URA+FqO/fcbags5m3dVhKRDNZTm8P3gPeBxwnWdGhw9/rwkdmJAXoc61BfUcSarbtpa9N60iKSmbpNDu7+eWAKwRrS/wS8ZGa3hiu1Zb6hRTBsRLfdWfcdbGP9zn0pCExEJPF67K3kgT8AXwH+C7gcOC0ZgQ0KvXVnVbuDiGSobpODmRWZ2f8ys98AjwHFwDR3vztp0aVaWV3MmsPR7d1ZNY2GiGSonhqkNwFvEfRSWknQCH2imZ0I4O6/Tnx4KVZWB28+Ae5gh9rjRw7Pp2io1pMWkczVU3J4kCAhHB8+IjmQ+cmhtA5a9sGuTTD8yI5iM6O+skhTd4tIxuo2Obj73CTGMThFTt0dkRwgWPhn2dr3UxCUiEjixTN9RvbqGOsQa+ruIpre38u+g61R+0RE0p2SQ086xjrE7s7qDu9u25PkoEREEi+exX7y4ynLSPnDobA8dnKo0AR8IpK54qk5/CXOsszUzViHMRXDAK0nLSKZqaeJ96qAUUChmU3l0NxKJcCwJMQ2OJTVweY3o4qHFwxh5PB8dWcVkYzUU1fWjwJzgRrg9ojyZuBrCYxpcCkbDW89HTXWAbRkqIhkrp66sv4E+ImZne/uv0piTINLaS207IXdW6C4stOuhspiHl++PkWBiYgkTjxtDgvN7HYzWxw+/tPMShMe2WBRcUzwvOnVqF1HVxbx/p6DvL/7QJKDEhFJrHiSw48JbiV9InzsBO5NZFCDyqjG4Lnphahd7RPwqVFaRDJNr8uEAke7+/kRr79pZssSFM/gU1gGlR+AtdHJIXI96RNGlyc5MBGRxImn5rDXzE5uf2FmJwF7ExfSIFR7YpAc2to6FdeUF5Kn9aRFJAPFkxyuBn5gZmvM7B3g+8BViQ1rkKmdAfu2w9aVnYqH5OZQN2KYurOKSMbp9baSuy8DJptZSfh6Z6KDGnRqZwTPa5+HyrGddjWoO6uIZKB4ps8oNbPbgd8Dv8+63koAI44JptFY+3zUrobKYlZv3U2r1pMWkQwSz22le8jm3koQDH6rnRGzUbq+oogDLW2s255dzTAiktniSQ5Hu/uN7r4qfHwTaEh0YINOzYmw5Q3Ys61TcYO6s4pIBlJvpXi1tzu8t6RTcX1lkBxWa3ZWEckg8YxzuJpgGo1Sgsn3tgGXJTSqwWjUNLDcoN3h2NM7iiuL8xmen6eag4hklF5rDu6+zN0nA5OAicCJ4XOPzOweM9tkZssjyo4ws6fM7K3wuTxi31fNbKWZvWFmH+3b6STQ0CKomhjVKN2+nrR6LIlIJuk2OZhZSfg/7O+b2ekEjdKfBFYSNEz35j7gjC5l/wIsdPdjgYXha8xsHHAxMD78zJ1mlnuY55J4tdOhaQm0tnQqbqgo0lgHEckoPdUcfgYcB/wNuBJ4ErgQONfdz+ntwO6+iOAWVKRzgJ+E2z8Bzo0on+/u+919NUECmh7nOSRP7Qw4uBs2rehUXF9RzHvbtZ60iGSOntocGtx9IoCZ/QjYAtS5e3M/vu9Id18P4O7rzWxkWD4K+GvE+5rCsihm9mng0wB1dXX9CKUPasN8tfYFqJ7cUdzQ3ii9ZTcfqC5JbkwiIgnQU83hYPuGu7cCq/uZGHpiMcpijipz97vcvdHdGysrK2O9JXFKa2F4ddR4h/bZWdXuICKZoqeaw2Qza58qwwiWC90Zbru79+VP5I1mVh3WGqqBTWF5E1Ab8b4aYF0fjp9YZsF4hy6N0u01h1XqzioiGaLbmoO757p7SfgY7u55Edt9vXfyCIe6wV4G/Cai/GIzyzezeuBYIHo48mBQOwO2vwPNGzqKhg3No7q0QI3SIpIx4hkE1ydm9gDwF+A4M2sys08BtwCnm9lbwOnha9x9BbAAeBV4HLgmvJU1+HRMwhd9a0ljHUQkU8QzCK5P3H1ON7tO7eb984B5iYpnwFRPgtz8YGW4cWd3FDdUFvHIsnW4O2axmlBERNJHwmoOGSsvH46aGqPmUMzOfS1s03rSIpIBlBz6ovZEWPcStOzvKOpolNatJRHJAEoOfVE7A1oPwPqXO4raZ2ddrUZpEckASg59UdM+GO5Ql9aa8mEMyTXe3qLurCKS/pQc+mL4kVA+plO7Q26OMXpEkWoOIpIRlBz6qmZ6UHPwQwO5G9SdVUQyhJJDX9VOh10bYfu7HUX1lUW8s3W3JuATkbSn5NBXMQbDfejYSg62Oo++PPhm/hARORxKDn01chwMLQ4Gw4VmHj2CsUcWc8+f1+Aec95AEZG0oOTQV7l5MOqETj2WzIwrTqrntfU7+euqrktZiIikDyWH/qidDhuWw/5D3VfPnTqK8mFDuOfPq1MYmIhI/yg59EftDPBWWLe0o6hgSC6XzBjN069t5J2t6rkkIulJyaE/ahqD5y7rO/zT348m14z7nluT/JhERAaAkkN/FJZD5fGw9sVOxUeWFHDWpGoeXNxE876D3XxYRGTwUnLor5oTgx5LbW2diq84uZ5d+1tYsLgpRYGJiPSdkkN/1c6Ave/D1pWdiifVlNE4upz7nltNa5u6tYpIelFy6K+OwXDPR+264uR61m7by8LXNiY5KBGR/lFy6K8RxwRtDzGSw0fGHcmoskJ1axWRtKPk0F85OcEkfE0vRu3Ky83hspmj+euqbaxYtyMFwYmI9I2Sw0CoPRE2vx60PXRxUWMdw4bmcu+f1yQ/LhGRPlJyGAjt7Q5Ni6N2lQ4bwgUn1PDIsnVsbt4ftV9EZDBSchgIR00Dy43Z7gAwd+YYDrS2cf/z7yQ5MBGRvlFyGAj5xVA1odvk0FBZzCnHj+Tnf32H/S1a60FEBj8lh4FSMx3eWwqtLTF3X3FSPVt2HeDRl9cnOTARkcOn5DBQamfAgV2w6dWYu086Jlzr4U+rtdaDiAx6Sg4DpXZ68NzNraX2tR5eXb+T51drrQcRGdyUHAZKWR0UV3VaNrSrjrUe/qRBcSIyuCk5DBSzoPbw7l86Lf4TqX2th6de28i7W/ckOUARkfgpOQyk486EHWvh9nHw+Fdh69tRb9FaDyKSDpQcBtLki+FTT8HYj8ALd8P3psHPz4c3n+iY0rt9rYcFi9dqrQcRGbSUHAZS+62l838E16+A2f8KG1fALz4B35sKz30P9r7P5ScFaz08qLUeRGSQsnTuVtnY2OiLF0dPWTGotB6E1x4NahLvPgd5hTDpE3xxzXQeWl9OScEQyocNoWzY0I7nsmFDKI94XT5sKIVDc3AHB9yhzT18HRS2l0cyA4PwP2AY1rEd9KCK1PV3YSB/MyK/qev3dnnZLfdDMUaer9OxETNm67Jh4UZP33u4/yziPVZkrPEdOFZRdGFvP8Ou5+MDenW7+9LEf0UHi9yM8xeqi/78TLp+5+Fej77EUFGcz9gjh8f9/khmtsTdG3t8j5JDEm34W5AkXlkALXvZXjCKFs/B21rxtjbcHfe28BZUGzk4Fj4DONbxaOvy7G54x6f6xiN+wT3GP7BYZfGwHiKKta+n93eNpWtMfY0xHpFxtW8feo4ui4zJI0rbX/cl5t5+Xp23ifiNAbND8XWURUQWGWfHtnd5HSP+rno7n3iub7zHO5yfR/C69zgO/W7FvlZd44n+joH/f2qsn8E7I07i1M//qE/Hiyc55PXpyNI3VRPh7Dvg9G/CS/dT9t5isJwYD6PVczjQ5uxvgf0tbbR6+OvhESnBndz2f7IR5eHbiPzTLdbfAA6dfu27vrnzL3l/f+EP/YPr+udwzH/83fzpFXmUjk+GJ2LtJ2kE52AWFbbH2Oot5phlEVWyjvity/84LPia9usTFDmdfgre/jq+BBH187NYP9PI/WFMBsFd5IjqpB1KD5hh7uTQ1hHTofjawt8vj4g3NvOuvzPdnNfhVBejCzsd12Meq/vft87f3fWzEdepy7lap9eHYoj+jnivZ3c/my4vu/kDvnTU+Di+o++UHFKhsBxmfq7Ht+QCheFDRCTZ1CAtIiJRlBxERCSKkoOIiERJSXIws+vNbIWZLTezB8yswMyOMLOnzOyt8Lk8FbGJiEgKkoOZjQKuAxrdfQJB2+vFwL8AC939WGBh+FpERFIgVbeV8oBCM8sDhgHrgHOAn4T7fwKcm5rQREQk6cnB3d8DbgPeBdYDO9z9SeBId18fvmc9MDLZsYmISCAVt5XKCWoJ9cBRQJGZXXoYn/+0mS02s8WbN29OVJgiIlktFYPgTgNWu/tmADP7NTAT2Ghm1e6+3syqgU2xPuzudwF3hZ/dbGbvdHlLBbAlYdGnjs4r/WTquem80k/Xcxvd2wdSkRzeBf7OzIYBe4FTgcXAbuAy4Jbw+Te9HcjdK7uWmdni3uYMSUc6r/STqeem80o/fTm3pCcHd3/ezH4JLAVagJcIagLFwAIz+xRBArkw2bGJiEggJXMrufuNwI1divcT1CJERCTFMnGE9F2pDiBBdF7pJ1PPTeeVfg773NJ6PQcREUmMTKw5iIhIPyk5iIhIlIxJDmZ2hpm9YWYrzSyj5mUyszVm9jczW2ZmabQuamdmdo+ZbTKz5RFlaT/hYjfndZOZvRdes2VmdmYqY+wLM6s1sz+Y2WvhRJmfD8sz4Zp1d25pfd3CSUxfMLOXw/P6Zlh+2NcsI9oczCwXeBM4HWgCXgTmuPurKQ1sgJjZGoKJCtN6gI6ZfQjYBfw0nHQRM7sV2Obut4RJvdzdb0hlnIerm/O6Cdjl7relMrb+CAejVrv7UjMbDiwhmPNsLul/zbo7t0+QxtfNzAwocvddZjYE+BPweeA8DvOaZUrNYTqw0t1XufsBYD7BFB0yiLj7ImBbl+K0n3Cxm/NKe+6+3t2XhtvNwGvAKDLjmnV3bmnNA7vCl0PCh9OHa5YpyWEUsDbidRMZcKEjOPCkmS0xs0+nOpgBlskTLn7OzF4Jbzul3a2XSGY2BpgKPE+GXbMu5wZpft3MLNfMlhFMQfSUu/fpmmVKcrAYZel/v+yQk9x9GvAPwDXhbQwZ3H4IHA1MIZh9+D9TGk0/mFkx8CvgC+6+M9XxDKQY55b2183dW919ClADTDezCX05TqYkhyagNuJ1DcEaERnB3deFz5uAhwhuo2WKjeH93/b7wDEnXEw37r4x/EfaBtxNml6z8L71r4D73f3XYXFGXLNY55Yp1w3A3bcDzwBn0IdrlinJ4UXgWDOrN7OhBCvLPZLimAaEmRWFDWaYWRHwEWB5z59KK48QTLQIcU64mA7a/yGGPk4aXrOwcfPHwGvufnvErrS/Zt2dW7pfNzOrNLOycLuQYBbs1+nDNcuI3koAYZez7xIsO3qPu89LbUQDw8waCGoLEMyF9Yt0PTczewCYRTB98EaC+bUeBhYAdYQTLrp7WjXudnNeswhuTTiwBriq/Z5vujCzk4E/An8D2sLirxHcm0/3a9bduc0hja+bmU0iaHDOJfjjf4G7f8vMRnCY1yxjkoOIiAycTLmtJCIiA0jJQUREoig5iIhIFCUHERGJouQgIiJRlBxEemFmrRGzdC4byFl/zWxM5GyuIoNFStaQFkkze8PpCESyhmoOIn0UrrPxf8P5818ws2PC8tFmtjCcvG2hmdWF5Uea2UPhXPsvm9nM8FC5ZnZ3OP/+k+HIVpGUUnIQ6V1hl9tKF0Xs2+nu04HvE4zQJ9z+qbtPAu4H7gjL7wCedffJwDRgRVh+LPADdx8PbAfOT+jZiMRBI6RFemFmu9y9OEb5GuAUd18VTuK2wd1HmNkWgoVkDobl6929wsw2AzXuvj/iGGMIplU+Nnx9AzDE3f9PEk5NpFuqOYj0j3ez3d17Ytkfsd2K2gJlEFByEOmfiyKe/xJuP0cwMzDAJQRLNQIsBK6GjgVZSpIVpMjh0l8oIr0rDFfWave4u7d3Z803s+cJ/tCaE5ZdB9xjZl8GNgOXh+WfB+4ys08R1BCuJlhQRmTQUZuDSB+FbQ6N7r4l1bGIDDTdVhIRkSiqOYiISBTVHEREJIqSg4iIRFFyEBGRKEoOIiISRclBRESi/H+91lAoA9mI3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.08\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# Split the original training set into a reduced training set and a\n",
    "# validation set. \n",
    "validation_split = 0.25\n",
    "\n",
    "# Identify the feature and the label.\n",
    "my_feature = \"median_income\"    # the median income on a specific city block.\n",
    "my_label = \"median_house_value\" # the median house value on a specific city block.\n",
    "# That is, you're going to create a model that predicts house value based \n",
    "# solely on the neighborhood's median income.  \n",
    "\n",
    "# Discard any pre-existing version of the model.\n",
    "my_model = None\n",
    "\n",
    "# Invoke the functions to build and train the model.\n",
    "my_model = build_model(learning_rate)\n",
    "epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
    "                                    my_label, epochs, batch_size, \n",
    "                                    validation_split)\n",
    "\n",
    "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
    "                    history[\"val_root_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da6de9",
   "metadata": {},
   "source": [
    "Experiment with `validation_split` to answer the following questions:\n",
    "\n",
    "* With the training set shuffled, is the final loss for the training set closer to the final loss for the validation set?  \n",
    "* At what range of values of `validation_split` do the final loss values for the training set and validation set diverge meaningfully?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee930c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, after shuffling the original training set, \n",
    "# the final loss for the training set and the \n",
    "# validation set become much closer.\n",
    "\n",
    "# If validation_split < 0.15,\n",
    "# the final loss values for the training set and\n",
    "# validation set diverge meaningfully.  Apparently,\n",
    "# the validation set no longer contains enough examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2319c5f",
   "metadata": {},
   "source": [
    "## Task 4: Use the Test Dataset to Evaluate Your Model's Performance\n",
    "\n",
    "The test set usually acts as the ultimate judge of a model's quality. The test set can serve as an impartial judge because its examples haven't been used in training the model. Run the following code cell to evaluate the model with the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03ead18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 7011.6226 - root_mean_squared_error: 83.7354\n"
     ]
    }
   ],
   "source": [
    "x_test = test_df[my_feature]\n",
    "y_test = test_df[my_label]\n",
    "\n",
    "results = my_model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ae155",
   "metadata": {},
   "source": [
    "Compare the root mean squared error of the model when evaluated on each of the three datasets:\n",
    "\n",
    "* training set: look for `root_mean_squared_error` in the final training epoch.\n",
    "* validation set: look for `val_root_mean_squared_error` in the final training epoch.\n",
    "* test set: run the preceding code cell and examine the `root_mean_squared_error`.\n",
    "\n",
    "Ideally, the root mean squared error of all three sets should be similar. Are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b18b2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our experiments, yes, the rmse values \n",
    "# were similar enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8470a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_google",
   "language": "python",
   "name": "ml_google"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
